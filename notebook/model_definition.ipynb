{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from seqmodel.bunch import Bunch\n",
    "from seqmodel import model\n",
    "from seqmodel import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_vocab = data.Vocabulary.from_vocab_file('../data/common_wordnet_defs/lemma_senses/dec_vocab.txt')\n",
    "enc_vocab = data.Vocabulary.from_vocab_file('../data/common_wordnet_defs/lemma_senses/enc_vocab.txt')\n",
    "char_vocab = data.Vocabulary.from_vocab_file('../data/common_wordnet_defs/lemma_senses/char_vocab.txt')\n",
    "valid_iter = data.Word2DefIterator(enc_vocab, dec_vocab, char_vocab)\n",
    "valid_iter.initialize('../data/common_wordnet_defs/lemma_senses/valid.txt',\n",
    "                      feature_source='../data/common_wordnet_defs/lemma_senses/valid_features.txt')\n",
    "valid_iter.init_batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/encoder_embedding:0, (31267, 10)\n",
      "model/decoder_embedding:0, (27665, 10)\n",
      "model/char_embedding:0, (28, 28)\n",
      "model/shared_rnn/rnn/basic_lstm_cell/weights:0, (20, 40)\n",
      "model/shared_rnn/rnn/basic_lstm_cell/biases:0, (40,)\n",
      "model/char_cnn/filter_2:0, (1, 2, 28, 10)\n",
      "model/char_cnn/filter_3:0, (1, 3, 28, 30)\n",
      "model/char_cnn/filter_4:0, (1, 4, 28, 40)\n",
      "model/char_cnn/filter_5:0, (1, 5, 28, 40)\n",
      "model/char_cnn/filter_6:0, (1, 6, 28, 40)\n",
      "model/decoder_rnn/gate_w:0, (190, 20)\n",
      "model/decoder_rnn/gate_b:0, (20,)\n",
      "model/decoder_rnn/logit_b:0, (27665,)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model_opt = model.definition_model.DefinitionModel.default_opt()\n",
    "model_opt.embedding.decoder_dim = 10\n",
    "model_opt.embedding.decoder_vocab_size = dec_vocab.vocab_size\n",
    "model_opt.embedding.encoder_dim = 10\n",
    "model_opt.embedding.encoder_vocab_size = enc_vocab.vocab_size\n",
    "model_opt.decoder.rnn_opt.logit.out_vocab_size = dec_vocab.vocab_size\n",
    "model_opt.decoder.rnn_opt.rnn_cell.cell_opt.num_units = 10\n",
    "model_opt.encoder.rnn_opt.rnn_cell.cell_opt.num_units = 10\n",
    "model_opt.decoder.share.encoder_rnn_params = True\n",
    "model_opt.decoder.share.encoder_embedding = False\n",
    "model_opt.decoder.share.logit_weight_tying = True\n",
    "model_fn = model.definition_model.DefinitionModel(model_opt)\n",
    "dm = model_fn(is_training=True)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "g_v_pairs =  optimizer.compute_gradients(dm.training_loss, tf.trainable_variables())\n",
    "train_op = optimizer.apply_gradients(g_v_pairs)\n",
    "for v in tf.trainable_variables():\n",
    "    print(\"{}, {}\".format(v.name, v.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "sess = tf.Session(config = sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "batch = valid_iter.next_batch()\n",
    "state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction, state, info = dm.predict(sess, batch.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_loss, state, info = dm.evaluate(sess, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_loss, train_loss, state, info = dm.train(sess, batch, train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.156315"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "873.44312"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
