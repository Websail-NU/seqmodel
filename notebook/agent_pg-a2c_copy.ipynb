{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from seqmodel.bunch import Bunch\n",
    "from seqmodel.experiment.policy_agent import ActorCriticAgent\n",
    "from seqmodel import model\n",
    "from seqmodel import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = data.Vocabulary.from_vocab_file('../data/tiny_copy/vocab.txt')\n",
    "valid_iter = data.Seq2SeqIterator(vocab, vocab)\n",
    "valid_iter.initialize('../data/tiny_copy/valid.txt')\n",
    "train_iter = data.Seq2SeqIterator(vocab, vocab)\n",
    "train_iter.initialize('../data/tiny_copy/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[INFO ]\u001b[0mep: 0, lr: 0.300000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_agent/policy/model/encoder_embedding:0, (15, 32)\n",
      "policy_agent/policy/model/decoder_embedding:0, (15, 32)\n",
      "policy_agent/policy/model/encoder_rnn/rnn/basic_lstm_cell/weights:0, (64, 128)\n",
      "policy_agent/policy/model/encoder_rnn/rnn/basic_lstm_cell/biases:0, (128,)\n",
      "policy_agent/policy/model/decoder_rnn/rnn/basic_lstm_cell/weights:0, (64, 128)\n",
      "policy_agent/policy/model/decoder_rnn/rnn/basic_lstm_cell/biases:0, (128,)\n",
      "policy_agent/policy/model/decoder_rnn/logit_w:0, (15, 32)\n",
      "policy_agent/policy/model/decoder_rnn/logit_b:0, (15,)\n",
      "policy_agent/value/model/encoder_embedding:0, (15, 32)\n",
      "policy_agent/value/model/decoder_embedding:0, (15, 32)\n",
      "policy_agent/value/model/encoder_rnn/rnn/basic_lstm_cell/weights:0, (64, 128)\n",
      "policy_agent/value/model/encoder_rnn/rnn/basic_lstm_cell/biases:0, (128,)\n",
      "policy_agent/value/model/decoder_rnn/rnn/basic_lstm_cell/weights:0, (64, 128)\n",
      "policy_agent/value/model/decoder_rnn/rnn/basic_lstm_cell/biases:0, (128,)\n",
      "policy_agent/value/model/decoder_rnn/regression_w:0, (1, 32)\n",
      "policy_agent/value/model/decoder_rnn/regression_b:0, (1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[INFO ]\u001b[0mtrain: @499 tr_loss: 8.75940, eval_loss: 1.33140 (3.78634), wps: 15345.9\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @49 eval_loss: 0.49504 (1.64056), wps: 31225.5\n",
      "\u001b[36m[INFO ]\u001b[0mep: 1, lr: 0.300000\n",
      "\u001b[36m[INFO ]\u001b[0mtrain: @499 tr_loss: 2.08008, eval_loss: 0.31413 (1.36907), wps: 15619.9\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @49 eval_loss: 0.24724 (1.28048), wps: 36564.7\n",
      "\u001b[36m[INFO ]\u001b[0mep: 2, lr: 0.300000\n",
      "\u001b[36m[INFO ]\u001b[0mtrain: @499 tr_loss: 1.14843, eval_loss: 0.17270 (1.18851), wps: 15497.4\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @49 eval_loss: 0.17177 (1.18741), wps: 35876.5\n",
      "\u001b[36m[INFO ]\u001b[0mep: 3, lr: 0.300000\n",
      "\u001b[36m[INFO ]\u001b[0mtrain: @499 tr_loss: 0.78560, eval_loss: 0.11829 (1.12557), wps: 15673.9\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @49 eval_loss: 0.10460 (1.11027), wps: 37163.1\n",
      "\u001b[36m[INFO ]\u001b[0mep: 4, lr: 0.300000\n",
      "\u001b[36m[INFO ]\u001b[0mtrain: @499 tr_loss: 0.58187, eval_loss: 0.08775 (1.09171), wps: 15368.8\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @49 eval_loss: 0.08459 (1.08827), wps: 28585.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seqmodel.experiment.run_info.TrainingState at 0x7fe77815a510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "agent_opt = ActorCriticAgent.default_opt()\n",
    "emb_opt = agent_opt.policy_model.model_opt.embedding\n",
    "dec_opt = agent_opt.policy_model.model_opt.decoder\n",
    "enc_opt = agent_opt.policy_model.model_opt.encoder\n",
    "optim_opt = agent_opt.optim\n",
    "\n",
    "agent_opt.discount_factor = 1.0\n",
    "\n",
    "emb_opt.decoder_dim = 32\n",
    "emb_opt.encoder_dim = 32\n",
    "\n",
    "dec_opt.rnn_opt.rnn_cell.cell_opt.num_units = 32\n",
    "enc_opt.rnn_opt.rnn_cell.cell_opt.num_units = 32\n",
    "\n",
    "optim_opt.learning_rate = 0.3\n",
    "optim_opt.name = 'GradientDescentOptimizer'\n",
    "optim_opt.max_epochs = 5\n",
    "\n",
    "emb_opt = agent_opt.value_model.model_opt.embedding\n",
    "dec_opt = agent_opt.value_model.model_opt.decoder\n",
    "enc_opt = agent_opt.value_model.model_opt.encoder\n",
    "\n",
    "emb_opt.decoder_dim = 32\n",
    "emb_opt.encoder_dim = 32\n",
    "\n",
    "dec_opt.rnn_opt.rnn_cell.cell_opt.num_units = 32\n",
    "enc_opt.rnn_opt.rnn_cell.cell_opt.num_units = 32\n",
    "\n",
    "sess_config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "sess = tf.Session(config = sess_config)\n",
    "\n",
    "agent = ActorCriticAgent(agent_opt, sess)\n",
    "agent.initialize_model(with_training=True)\n",
    "agent.initialize_optim()\n",
    "for v in tf.trainable_variables():\n",
    "    print('{}, {}'.format(v.name, v.get_shape()))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "agent.train(train_iter, 20, valid_iter, 20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL: 0.0845933976382]\n",
      "Each match: -0.958009126984\n",
      "Exact match: -0.845\n",
      "BLEU: -0.917033496979\n"
     ]
    }
   ],
   "source": [
    "info = agent.evaluate(valid_iter, 20)\n",
    "print(\"PPL: {}]\".format(\n",
    "    info.eval_cost/info.num_tokens))\n",
    "\n",
    "valid_env = data.env.CopyEnv(valid_iter, re_init=False, reward_mode=data.env.ToyRewardMode.EACH_MATCH)\n",
    "valid_env.restart(batch_size=20)\n",
    "info = agent.evaluate_policy(valid_env)\n",
    "print('Each match: {}'.format(info.eval_loss))\n",
    "\n",
    "valid_hard_env = data.env.CopyEnv(valid_iter, re_init=False, reward_mode=data.env.ToyRewardMode.ALL_MATCH)\n",
    "valid_hard_env.restart(batch_size=20)\n",
    "info = agent.evaluate_policy(valid_hard_env)\n",
    "print('Exact match: {}'.format(info.eval_loss))\n",
    "\n",
    "valid_bleu_env = data.env.CopyEnv(valid_iter, re_init=False, reward_mode=data.env.ToyRewardMode.SEN_BLEU)\n",
    "valid_bleu_env.restart(batch_size=20)\n",
    "info = agent.evaluate_policy(valid_bleu_env)\n",
    "print('BLEU: {}'.format(info.eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[INFO ]\u001b[0mep: 0, lr: 0.300000\n",
      "\u001b[36m[INFO ]\u001b[0mtrain: @500 tr_loss: -0.10057, base_loss: 0.02064, avg_return: 0.93499, wps: 3858.3\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @50 avg_return: 0.89100, wps: 8995.6\n",
      "\u001b[36m[INFO ]\u001b[0mep: 1, lr: 0.300000\n",
      "\u001b[36m[INFO ]\u001b[0mtrain: @500 tr_loss: -0.09817, base_loss: 0.01208, avg_return: 0.94365, wps: 3972.9\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @50 avg_return: 0.89000, wps: 8954.8\n",
      "\u001b[36m[INFO ]\u001b[0mep: 2, lr: 0.300000\n",
      "\u001b[36m[INFO ]\u001b[0mtrain: @500 tr_loss: -0.09995, base_loss: 0.01084, avg_return: 0.94547, wps: 3975.0\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @50 avg_return: 0.88400, wps: 8660.5\n",
      "\u001b[36m[INFO ]\u001b[0mep: 3, lr: 0.300000\n",
      "\u001b[36m[INFO ]\u001b[0mtrain: @500 tr_loss: -0.09916, base_loss: 0.01001, avg_return: 0.94777, wps: 3976.1\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @50 avg_return: 0.89300, wps: 9082.8\n",
      "\u001b[36m[INFO ]\u001b[0mep: 4, lr: 0.300000\n",
      "\u001b[36m[INFO ]\u001b[0mtrain: @500 tr_loss: -0.09278, base_loss: 0.00941, avg_return: 0.95108, wps: 3951.1\n",
      "\u001b[36m[INFO ]\u001b[0mvalid: @50 avg_return: 0.90400, wps: 9084.4\n"
     ]
    }
   ],
   "source": [
    "agent.reset_training_state()\n",
    "train_env = data.env.CopyEnv(train_iter, re_init=False, reward_mode=data.env.ToyRewardMode.EACH_MATCH)\n",
    "info = agent.policy_gradient(train_env, 20, valid_hard_env, 20, max_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL: 0.0621478553859\n",
      "Each match: 0.975246428571\n",
      "Exact match: 0.904\n",
      "BLEU: 0.943561717181\n"
     ]
    }
   ],
   "source": [
    "info = agent.evaluate(valid_iter, 20)\n",
    "print(\"PPL: {}\".format(\n",
    "    info.eval_cost/info.num_tokens))\n",
    "\n",
    "valid_env = data.env.CopyEnv(valid_iter, re_init=False, reward_mode=data.env.ToyRewardMode.EACH_MATCH)\n",
    "valid_env.restart(batch_size=20)\n",
    "info = agent.evaluate_policy(valid_env)\n",
    "print('Each match: {}'.format(-1 * info.eval_loss))\n",
    "\n",
    "valid_hard_env = data.env.CopyEnv(valid_iter, re_init=False, reward_mode=data.env.ToyRewardMode.ALL_MATCH)\n",
    "valid_hard_env.restart(batch_size=20)\n",
    "info = agent.evaluate_policy(valid_hard_env)\n",
    "print('Exact match: {}'.format(-1 * info.eval_loss))\n",
    "\n",
    "valid_bleu_env = data.env.CopyEnv(valid_iter, re_init=False, reward_mode=data.env.ToyRewardMode.SEN_BLEU)\n",
    "valid_bleu_env.restart(batch_size=20)\n",
    "info = agent.evaluate_policy(valid_bleu_env)\n",
    "print('BLEU: {}'.format(-1 * info.eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return: \n",
      "[[-0.01575243 -0.00287337  0.01562468  0.00134041 -0.03334575 -0.10050561\n",
      "  -0.10050561 -0.10050561 -0.10050561 -0.10050561]\n",
      " [-0.33200121 -0.37118188 -0.39225872 -0.3926519  -0.30676489 -0.21994679\n",
      "  -0.21045455 -0.13292591 -0.0579662   0.00362953]]\n",
      "Target: \n",
      "[[ 1.   0.8  0.6  0.4  0.2  0.   0.   0.   0.   0. ]\n",
      " [ 0.5  0.4  0.3  0.2  0.2  0.2  0.1  0.1  0.1  0.1]]\n"
     ]
    }
   ],
   "source": [
    "test_data = ([['a a b c a d a f a', 'a a b c a d a f a'], ['a b c d', 'a b c d']])\n",
    "test_iter = data.Seq2SeqIterator(vocab, vocab)\n",
    "test_iter.initialize(test_data)\n",
    "test_iter.init_batch(2)\n",
    "env = data.env.CopyEnv(test_iter, re_init=False, reward_mode=data.env.ToyRewardMode.EACH_MATCH)\n",
    "# env = data.env.Seq2SeqEnv(test_iter, re_init=False)\n",
    "transitions, states, rewards = agent.rollout(env, greedy=True)\n",
    "rewards = np.array(rewards)\n",
    "returns, targets = agent._compute_return(states, rewards)\n",
    "print('Return: ') \n",
    "print(returns.T)\n",
    "print('Target: ')\n",
    "print(targets.T)\n",
    "pg_data = env.create_transition_return(states, returns)\n",
    "val_data = env.create_transition_value(states, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  6,  7,  8,  3,  3,  3,  3,  3,  3],\n",
       "       [ 1,  5,  5,  6,  7,  5,  8,  5, 10,  5,  3]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_data.features.encoder_input.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  6,  7,  8,  0,  0,  0,  0,  0,  0],\n",
       "       [ 5,  5,  6,  5,  7,  8, 10,  5,  9,  0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_data.labels.decoder_label.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01575243, -0.00287337,  0.01562468,  0.00134041, -0.03334575,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ],\n",
       "       [-0.33200121, -0.37118188, -0.39225872, -0.3926519 , -0.30676489,\n",
       "        -0.21994679, -0.21045455, -0.13292591, -0.0579662 ,  0.00362953]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_data.labels.decoder_label_weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
