{
  "lr:decay_every": 1,
  "lr:decay_factor": 1.0,
  "lr:imp_ratio_threshold": 0.0,
  "lr:imp_wait": 2,
  "lr:min_lr": 1e-06,
  "lr:start_decay_at": 1,
  "optim:epsilon": 1e-08,
  "train:clip_gradients": 10.0,
  "train:init_lr": 0.001,
  "train:max_epoch": 10,
  "train:optim_class": "tensorflow.train.AdamOptimizer"
}